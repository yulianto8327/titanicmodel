{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"},{"sourceId":10242375,"sourceType":"datasetVersion","datasetId":6334113},{"sourceId":10242496,"sourceType":"datasetVersion","datasetId":6334187},{"sourceId":10242649,"sourceType":"datasetVersion","datasetId":6334286},{"sourceId":10243179,"sourceType":"datasetVersion","datasetId":6334476}],"dockerImageVersionId":29507,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yuliantow/titanic-randomforestclassifier-and-xgbc?scriptVersionId=214377183\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport xgboost as xgb\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef clean_data(df):\n    \"\"\"\n    Cleans the dataset by handling missing values, infinite values, and preparing it for analysis.\n    \n    Parameters:\n    - df: pd.DataFrame - The dataset to clean.\n    \n    Returns:\n    - cleaned_df: pd.DataFrame - The cleaned dataset.\n    \"\"\"\n    print(\"\\nCleaning Data...\")\n    # Replace infinities with NaN\n    df.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n    \n    # Report missing values before cleaning\n    missing_before = df.isnull().sum().sum()\n    print(f\"Missing values before cleaning: {missing_before}\")\n    \n    # Fill NaN values with column means for numerical features\n    df.fillna(df.mean(numeric_only=True), inplace=True)\n    \n    # Report missing values after cleaning\n    missing_after = df.isnull().sum().sum()\n    print(f\"Missing values after cleaning: {missing_after}\")\n    \n    return df\n    \ndef analyze_data(df, target_column=None, correlation_columns=None, plot_columns=None, calculate_mi=False):\n    \"\"\"\n    Analyze data by calculating statistics, correlations, unique values, empty values, and creating visualizations.\n    \n    Parameters:\n    - df: pd.DataFrame - The dataset to analyze.\n    - target_column: str - The target column for correlation analysis.\n    - correlation_columns: list - List of columns to calculate correlations with the target column.\n    - plot_columns: list - List of columns to visualize trends or distributions.\n    \n    Returns:\n    - stats: pd.DataFrame - Summary statistics of the dataset.\n    - correlations: pd.Series or None - Correlations with the target column, if specified.\n    - unique_values: pd.Series - Count of unique values per column.\n    - empty_values: pd.Series - Count of empty (NaN) values per column.\n    \"\"\"\n    \n    print(\"\\nColumns:\")\n    print(df.columns)\n    \n    # 1. Display descriptive statistics\n    print(\"\\nDescriptive Statistics:\")\n    stats = df.describe(include='all')\n    print(stats)\n    \n    # 2. Check unique values\n    print(\"\\nUnique Values per Column:\")\n    unique_values = df.nunique()\n    print(unique_values)\n    \n    # 3. Check empty (NaN) values\n    print(\"\\nEmpty (NaN) Values per Column:\")\n    empty_values = df.isnull().sum()\n    print(empty_values)\n    \n    # 4. Calculate correlations\n    correlations = None\n    if target_column:\n        if correlation_columns is None:\n            correlation_columns = [col for col in df.columns if col != target_column]\n        print(f\"\\nCorrelations with '{target_column}':\")\n        correlations = df[correlation_columns].corrwith(df[target_column]).abs().sort_values(ascending=False)\n        print(correlations)\n    \n    # 5. Visualize data\n    if plot_columns:\n        print(\"\\nVisualizing data:\")\n        for column in plot_columns:\n            if pd.api.types.is_numeric_dtype(df[column]):\n                # Histogram for numerical data\n                sns.histplot(df[column], kde=True)\n                plt.title(f\"Distribution of {column}\")\n                plt.show()\n            else:\n                # Bar plot for categorical data\n                sns.countplot(data=df, x=column)\n                plt.title(f\"Countplot of {column}\")\n                plt.show()\n    \n    # 6. Calculate MI scores\n    mi_scores = None\n    if calculate_mi and target_column:\n        print(\"\\nMutual Information (MI) Scores:\")\n        df_encoded = pd.get_dummies(df, drop_first=True, dtype=int)\n        X = df_encoded.drop(columns=[target_column])\n        y = df_encoded[target_column]\n        mi_scores_array = mutual_info_regression(X, y, random_state=42)\n        mi_scores = pd.Series(mi_scores_array, index=X.columns).sort_values(ascending=False)\n        print(mi_scores)\n  \n    return stats, correlations, unique_values, empty_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T03:15:10.699628Z","iopub.execute_input":"2024-12-23T03:15:10.699951Z","iopub.status.idle":"2024-12-23T03:15:10.721002Z","shell.execute_reply.started":"2024-12-23T03:15:10.699904Z","shell.execute_reply":"2024-12-23T03:15:10.71988Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\ntd = pd.concat([train_data, test_data], ignore_index=True, sort  = False)\n\ntd['Age_Range'] = pd.cut(td.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\ntd[\"Family\"] = td.Parch + td.SibSp\ntd[\"Is_Alone\"] = td.Family == 0\ntd['Fare_Category'] = pd.cut(train_data['Fare'], bins=[0,7.90,14.45,31.28,120], labels=['Low','Mid',\n                                                                                      'High_Mid','High'])\ntd['Sex'] = LabelEncoder().fit_transform(td['Sex'])\ntd['Is_Alone'] = LabelEncoder().fit_transform(td['Is_Alone'])\n\nprint(train_data.head())\n#\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"AgeGroup\", \"Embarked\", \"FareRate\"\ndf = pd.DataFrame(train_data)\ncleaned_df = clean_data(df)\n\nstats, correlations, unique_values, empty_values = analyze_data(\n    cleaned_df,\n    target_column=\"Survived\",  # Example target column\n)\n\ntd = pd.concat([td,pd.get_dummies(td.Age_Range, prefix=\"Age_Range\"), pd.get_dummies(td.Embarked, prefix=\"Emb\", drop_first = True), pd.get_dummies(td.Fare_Category, prefix=\"Fare\", drop_first = True), pd.get_dummies(td.Pclass, prefix=\"Class\", drop_first = True)], axis=1)\n\ntd.drop(['Pclass', 'Fare','Cabin', 'Fare_Category','Name', 'Ticket','Embarked', 'Age_Range', 'SibSp', 'Parch', 'Age'], axis=1, inplace=True)\n\nprint(\"\\nFINAL DATA\\n\")\nprint(td.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T03:29:18.237679Z","iopub.execute_input":"2024-12-23T03:29:18.23808Z","iopub.status.idle":"2024-12-23T03:29:18.382363Z","shell.execute_reply.started":"2024-12-23T03:29:18.238028Z","shell.execute_reply":"2024-12-23T03:29:18.381383Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n\nCleaning Data...\nMissing values before cleaning: 866\nMissing values after cleaning: 689\n\nColumns:\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\nDescriptive Statistics:\n        PassengerId    Survived      Pclass                            Name  \\\ncount    891.000000  891.000000  891.000000                             891   \nunique          NaN         NaN         NaN                             891   \ntop             NaN         NaN         NaN  Coelho, Mr. Domingos Fernandeo   \nfreq            NaN         NaN         NaN                               1   \nmean     446.000000    0.383838    2.308642                             NaN   \nstd      257.353842    0.486592    0.836071                             NaN   \nmin        1.000000    0.000000    1.000000                             NaN   \n25%      223.500000    0.000000    2.000000                             NaN   \n50%      446.000000    0.000000    3.000000                             NaN   \n75%      668.500000    1.000000    3.000000                             NaN   \nmax      891.000000    1.000000    3.000000                             NaN   \n\n         Sex         Age       SibSp       Parch Ticket        Fare Cabin  \\\ncount    891  891.000000  891.000000  891.000000    891  891.000000   204   \nunique     2         NaN         NaN         NaN    681         NaN   147   \ntop     male         NaN         NaN         NaN   1601         NaN    G6   \nfreq     577         NaN         NaN         NaN      7         NaN     4   \nmean     NaN   29.699118    0.523008    0.381594    NaN   32.204208   NaN   \nstd      NaN   13.002015    1.102743    0.806057    NaN   49.693429   NaN   \nmin      NaN    0.420000    0.000000    0.000000    NaN    0.000000   NaN   \n25%      NaN   22.000000    0.000000    0.000000    NaN    7.910400   NaN   \n50%      NaN   29.699118    0.000000    0.000000    NaN   14.454200   NaN   \n75%      NaN   35.000000    1.000000    0.000000    NaN   31.000000   NaN   \nmax      NaN   80.000000    8.000000    6.000000    NaN  512.329200   NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  \n\nUnique Values per Column:\nPassengerId    891\nSurvived         2\nPclass           3\nName           891\nSex              2\nAge             89\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nEmbarked         3\ndtype: int64\n\nEmpty (NaN) Values per Column:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nCorrelations with 'Survived':\nPclass         0.338481\nFare           0.257307\nParch          0.081629\nAge            0.069809\nSibSp          0.035322\nPassengerId    0.005007\ndtype: float64\n\nFINAL DATA\n\n   PassengerId  Survived  Sex  Family  Is_Alone  Age_Range_(0, 10]  \\\n0            1       0.0    1       1         0                  0   \n1            2       1.0    0       1         0                  0   \n2            3       1.0    0       0         1                  0   \n3            4       1.0    0       1         0                  0   \n4            5       0.0    1       0         1                  0   \n\n   Age_Range_(10, 20]  Age_Range_(20, 30]  Age_Range_(30, 40]  \\\n0                   0                   1                   0   \n1                   0                   0                   1   \n2                   0                   1                   0   \n3                   0                   0                   1   \n4                   0                   0                   1   \n\n   Age_Range_(40, 50]  Age_Range_(50, 60]  Age_Range_(60, 70]  \\\n0                   0                   0                   0   \n1                   0                   0                   0   \n2                   0                   0                   0   \n3                   0                   0                   0   \n4                   0                   0                   0   \n\n   Age_Range_(70, 80]  Emb_Q  Emb_S  Fare_Mid  Fare_High_Mid  Fare_High  \\\n0                   0      0      1         0              0          0   \n1                   0      0      0         0              0          1   \n2                   0      0      1         1              0          0   \n3                   0      0      1         0              0          1   \n4                   0      0      1         1              0          0   \n\n   Class_2  Class_3  \n0        0        1  \n1        0        0  \n2        0        1  \n3        0        0  \n4        0        1  \n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Embarked\", \"Fare\"]\n\n#parameter drop_first=True = one-hot encoding, converting string to number value, RandomForestClassifier can only process int\n#X = pd.get_dummies(train_data[features], drop_first=True, dtype = int)\n#X_test = pd.get_dummies(test_data[features], drop_first=True, dtype = int)\n\n#X_test = X_test.reindex(columns=X.columns, fill_value=0)\n\nX_test = td[td.Survived.isnull()]\nX = td[td.Survived.notnull()]\n\nprint(X_test.info())\nprint(X.info())\n\n\n#model = RandomForestClassifier(n_estimators=500,random_state=1)\n#model.fit(X, y)\n#predictions = model.predict(X_test)\n\n#rf = RandomForestClassifier(n_estimators=500)\n#rf_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')","metadata":{"_kg_hide-output":false,"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T03:33:45.971101Z","iopub.execute_input":"2024-12-23T03:33:45.971436Z","iopub.status.idle":"2024-12-23T03:33:45.991843Z","shell.execute_reply.started":"2024-12-23T03:33:45.971378Z","shell.execute_reply":"2024-12-23T03:33:45.990918Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 418 entries, 891 to 1308\nData columns (total 20 columns):\nPassengerId           418 non-null int64\nSurvived              0 non-null float64\nSex                   418 non-null int64\nFamily                418 non-null int64\nIs_Alone              418 non-null int64\nAge_Range_(0, 10]     418 non-null uint8\nAge_Range_(10, 20]    418 non-null uint8\nAge_Range_(20, 30]    418 non-null uint8\nAge_Range_(30, 40]    418 non-null uint8\nAge_Range_(40, 50]    418 non-null uint8\nAge_Range_(50, 60]    418 non-null uint8\nAge_Range_(60, 70]    418 non-null uint8\nAge_Range_(70, 80]    418 non-null uint8\nEmb_Q                 418 non-null uint8\nEmb_S                 418 non-null uint8\nFare_Mid              418 non-null uint8\nFare_High_Mid         418 non-null uint8\nFare_High             418 non-null uint8\nClass_2               418 non-null uint8\nClass_3               418 non-null uint8\ndtypes: float64(1), int64(4), uint8(15)\nmemory usage: 25.7 KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 20 columns):\nPassengerId           891 non-null int64\nSurvived              891 non-null float64\nSex                   891 non-null int64\nFamily                891 non-null int64\nIs_Alone              891 non-null int64\nAge_Range_(0, 10]     891 non-null uint8\nAge_Range_(10, 20]    891 non-null uint8\nAge_Range_(20, 30]    891 non-null uint8\nAge_Range_(30, 40]    891 non-null uint8\nAge_Range_(40, 50]    891 non-null uint8\nAge_Range_(50, 60]    891 non-null uint8\nAge_Range_(60, 70]    891 non-null uint8\nAge_Range_(70, 80]    891 non-null uint8\nEmb_Q                 891 non-null uint8\nEmb_S                 891 non-null uint8\nFare_Mid              891 non-null uint8\nFare_High_Mid         891 non-null uint8\nFare_High             891 non-null uint8\nClass_2               891 non-null uint8\nClass_3               891 non-null uint8\ndtypes: float64(1), int64(4), uint8(15)\nmemory usage: 54.8 KB\nNone\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"**use XGBClassifier model which is better**# \n\nWe can loop the estimators to get the best one","metadata":{}},{"cell_type":"code","source":"\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X.columns if\n                    X[cname].nunique() < 10 and \n                    X[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the range of n_estimators to try\nn_estimators_range = [ 150, 200, 250, 400, 500, 600, 700]\n\n# Initialize variables to store best score and corresponding n_estimators\nbest_score = -np.inf\nbest_n_estimators = None\n\nfor n_estimators in n_estimators_range:\n    # Initialize the XGBoost model with the current n_estimators\n    model = xgb.XGBClassifier(n_estimators=n_estimators)\n    \n    # Perform cross-validation and compute the mean accuracy\n    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    mean_score = cv_scores.mean()\n    \n    print(f\"n_estimators: {n_estimators}, Mean Accuracy: {mean_score}\")\n    \n    # Update the best score and n_estimators if current score is better\n    if mean_score > best_score:\n        best_score = mean_score\n        best_n_estimators = n_estimators\n\n# Output the best n_estimators and its corresponding score\nprint(f\"\\nBest n_estimators: {best_n_estimators}, Best Mean Accuracy: {best_score}\")\n\nmodel = xgb.XGBClassifier(n_estimators=best_n_estimators)\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X, y)\n\n# Preprocessing of validation data, get predictions\npredictions_xgb = my_pipeline.predict(X_test)\n\n#score = mean_absolute_error(y, predictions_xgb)\n#print('MAE:', score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T03:33:05.237125Z","iopub.execute_input":"2024-12-23T03:33:05.237468Z","iopub.status.idle":"2024-12-23T03:33:05.301368Z","shell.execute_reply.started":"2024-12-23T03:33:05.237407Z","shell.execute_reply":"2024-12-23T03:33:05.300106Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n  FutureWarning)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-c09052a7371f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Perform cross-validation and compute the mean accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mmean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    868\u001b[0m                        \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                        for f in feature_names):\n\u001b[0;32m--> 870\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_names may not contain [, ] or <'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# reset feature_types also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: feature_names may not contain [, ] or <"],"ename":"ValueError","evalue":"feature_names may not contain [, ] or <","output_type":"error"}],"execution_count":67},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_xgb})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"_kg_hide-output":false,"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:42:09.961076Z","iopub.execute_input":"2024-12-23T01:42:09.961419Z","iopub.status.idle":"2024-12-23T01:42:09.970283Z","shell.execute_reply.started":"2024-12-23T01:42:09.961357Z","shell.execute_reply":"2024-12-23T01:42:09.969629Z"}},"outputs":[],"execution_count":null}]}