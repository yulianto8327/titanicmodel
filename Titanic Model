{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"},{"sourceId":10242375,"sourceType":"datasetVersion","datasetId":6334113},{"sourceId":10242496,"sourceType":"datasetVersion","datasetId":6334187},{"sourceId":10242649,"sourceType":"datasetVersion","datasetId":6334286},{"sourceId":10243179,"sourceType":"datasetVersion","datasetId":6334476}],"dockerImageVersionId":29507,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yuliantow/titanic-randomforestclassifier-and-xgbc?scriptVersionId=214385168\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport xgboost as xgb\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef clean_data(df):\n    \"\"\"\n    Cleans the dataset by handling missing values, infinite values, and preparing it for analysis.\n    \n    Parameters:\n    - df: pd.DataFrame - The dataset to clean.\n    \n    Returns:\n    - cleaned_df: pd.DataFrame - The cleaned dataset.\n    \"\"\"\n    print(\"\\nCleaning Data...\")\n    # Replace infinities with NaN\n    df.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n    \n    # Report missing values before cleaning\n    missing_before = df.isnull().sum().sum()\n    print(f\"Missing values before cleaning: {missing_before}\")\n    \n    # Fill NaN values with column means for numerical features\n    df.fillna(df.mean(numeric_only=True), inplace=True)\n    \n    # Report missing values after cleaning\n    missing_after = df.isnull().sum().sum()\n    print(f\"Missing values after cleaning: {missing_after}\")\n    \n    return df\n    \ndef analyze_data(df, target_column=None, correlation_columns=None, plot_columns=None, calculate_mi=False):\n    \"\"\"\n    Analyze data by calculating statistics, correlations, unique values, empty values, and creating visualizations.\n    \n    Parameters:\n    - df: pd.DataFrame - The dataset to analyze.\n    - target_column: str - The target column for correlation analysis.\n    - correlation_columns: list - List of columns to calculate correlations with the target column.\n    - plot_columns: list - List of columns to visualize trends or distributions.\n    \n    Returns:\n    - stats: pd.DataFrame - Summary statistics of the dataset.\n    - correlations: pd.Series or None - Correlations with the target column, if specified.\n    - unique_values: pd.Series - Count of unique values per column.\n    - empty_values: pd.Series - Count of empty (NaN) values per column.\n    \"\"\"\n    \n    print(\"\\nColumns:\")\n    print(df.columns)\n    \n    # 1. Display descriptive statistics\n    print(\"\\nDescriptive Statistics:\")\n    stats = df.describe(include='all')\n    print(stats)\n    \n    # 2. Check unique values\n    print(\"\\nUnique Values per Column:\")\n    unique_values = df.nunique()\n    print(unique_values)\n    \n    # 3. Check empty (NaN) values\n    print(\"\\nEmpty (NaN) Values per Column:\")\n    empty_values = df.isnull().sum()\n    print(empty_values)\n    \n    # 4. Calculate correlations\n    correlations = None\n    if target_column:\n        if correlation_columns is None:\n            correlation_columns = [col for col in df.columns if col != target_column]\n        print(f\"\\nCorrelations with '{target_column}':\")\n        correlations = df[correlation_columns].corrwith(df[target_column]).abs().sort_values(ascending=False)\n        print(correlations)\n    \n    # 5. Visualize data\n    if plot_columns:\n        print(\"\\nVisualizing data:\")\n        for column in plot_columns:\n            if pd.api.types.is_numeric_dtype(df[column]):\n                # Histogram for numerical data\n                sns.histplot(df[column], kde=True)\n                plt.title(f\"Distribution of {column}\")\n                plt.show()\n            else:\n                # Bar plot for categorical data\n                sns.countplot(data=df, x=column)\n                plt.title(f\"Countplot of {column}\")\n                plt.show()\n    \n    # 6. Calculate MI scores\n    mi_scores = None\n    if calculate_mi and target_column:\n        print(\"\\nMutual Information (MI) Scores:\")\n        df_encoded = pd.get_dummies(df, drop_first=True, dtype=int)\n        X = df_encoded.drop(columns=[target_column])\n        y = df_encoded[target_column]\n        mi_scores_array = mutual_info_regression(X, y, random_state=42)\n        mi_scores = pd.Series(mi_scores_array, index=X.columns).sort_values(ascending=False)\n        print(mi_scores)\n  \n    return stats, correlations, unique_values, empty_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:01:14.344798Z","iopub.execute_input":"2024-12-23T05:01:14.345179Z","iopub.status.idle":"2024-12-23T05:01:14.370465Z","shell.execute_reply.started":"2024-12-23T05:01:14.345127Z","shell.execute_reply":"2024-12-23T05:01:14.368802Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\ntd = pd.concat([train_data, test_data], ignore_index=True, sort  = False)\n\ntd['Age_Range'] = pd.cut(td.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\ntd[\"Family\"] = td.Parch + td.SibSp\ntd[\"Is_Alone\"] = td.Family == 0\ntd['Fare_Category'] = pd.cut(train_data['Fare'], bins=[0,7.90,14.45,31.28,120], labels=['Low','Mid',\n                                                                                      'High_Mid','High'])\ntd['Sex'] = LabelEncoder().fit_transform(td['Sex'])\ntd['Is_Alone'] = LabelEncoder().fit_transform(td['Is_Alone'])\n\nprint(train_data.head())\n#\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"AgeGroup\", \"Embarked\", \"FareRate\"\ndf = pd.DataFrame(train_data)\ncleaned_df = clean_data(df)\n\nstats, correlations, unique_values, empty_values = analyze_data(\n    cleaned_df,\n    target_column=\"Survived\",  # Example target column\n)\n\ntd = pd.concat([td,pd.get_dummies(td.Age_Range, prefix=\"Age_Range\"), pd.get_dummies(td.Embarked, prefix=\"Emb\", drop_first = True), pd.get_dummies(td.Fare_Category, prefix=\"Fare\", drop_first = True), pd.get_dummies(td.Pclass, prefix=\"Class\", drop_first = True)], axis=1)\n\ntd.drop(['Pclass', 'Fare','Cabin', 'Fare_Category','Name', 'Ticket','Embarked', 'Age_Range', 'SibSp', 'Parch', 'Age'], axis=1, inplace=True)\n\nprint(\"\\nFINAL DATA\\n\")\nprint(td.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:01:14.372927Z","iopub.execute_input":"2024-12-23T05:01:14.373281Z","iopub.status.idle":"2024-12-23T05:01:14.558698Z","shell.execute_reply.started":"2024-12-23T05:01:14.37323Z","shell.execute_reply":"2024-12-23T05:01:14.557535Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n\nCleaning Data...\nMissing values before cleaning: 866\nMissing values after cleaning: 689\n\nColumns:\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\nDescriptive Statistics:\n        PassengerId    Survived      Pclass                        Name   Sex  \\\ncount    891.000000  891.000000  891.000000                         891   891   \nunique          NaN         NaN         NaN                         891     2   \ntop             NaN         NaN         NaN  Chapman, Mr. Charles Henry  male   \nfreq            NaN         NaN         NaN                           1   577   \nmean     446.000000    0.383838    2.308642                         NaN   NaN   \nstd      257.353842    0.486592    0.836071                         NaN   NaN   \nmin        1.000000    0.000000    1.000000                         NaN   NaN   \n25%      223.500000    0.000000    2.000000                         NaN   NaN   \n50%      446.000000    0.000000    3.000000                         NaN   NaN   \n75%      668.500000    1.000000    3.000000                         NaN   NaN   \nmax      891.000000    1.000000    3.000000                         NaN   NaN   \n\n               Age       SibSp       Parch Ticket        Fare    Cabin  \\\ncount   891.000000  891.000000  891.000000    891  891.000000      204   \nunique         NaN         NaN         NaN    681         NaN      147   \ntop            NaN         NaN         NaN   1601         NaN  B96 B98   \nfreq           NaN         NaN         NaN      7         NaN        4   \nmean     29.699118    0.523008    0.381594    NaN   32.204208      NaN   \nstd      13.002015    1.102743    0.806057    NaN   49.693429      NaN   \nmin       0.420000    0.000000    0.000000    NaN    0.000000      NaN   \n25%      22.000000    0.000000    0.000000    NaN    7.910400      NaN   \n50%      29.699118    0.000000    0.000000    NaN   14.454200      NaN   \n75%      35.000000    1.000000    0.000000    NaN   31.000000      NaN   \nmax      80.000000    8.000000    6.000000    NaN  512.329200      NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  \n\nUnique Values per Column:\nPassengerId    891\nSurvived         2\nPclass           3\nName           891\nSex              2\nAge             89\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nEmbarked         3\ndtype: int64\n\nEmpty (NaN) Values per Column:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nCorrelations with 'Survived':\nPclass         0.338481\nFare           0.257307\nParch          0.081629\nAge            0.069809\nSibSp          0.035322\nPassengerId    0.005007\ndtype: float64\n\nFINAL DATA\n\n   PassengerId  Survived  Sex  Family  Is_Alone  Age_Range_(0, 10]  \\\n0            1       0.0    1       1         0                  0   \n1            2       1.0    0       1         0                  0   \n2            3       1.0    0       0         1                  0   \n3            4       1.0    0       1         0                  0   \n4            5       0.0    1       0         1                  0   \n\n   Age_Range_(10, 20]  Age_Range_(20, 30]  Age_Range_(30, 40]  \\\n0                   0                   1                   0   \n1                   0                   0                   1   \n2                   0                   1                   0   \n3                   0                   0                   1   \n4                   0                   0                   1   \n\n   Age_Range_(40, 50]  Age_Range_(50, 60]  Age_Range_(60, 70]  \\\n0                   0                   0                   0   \n1                   0                   0                   0   \n2                   0                   0                   0   \n3                   0                   0                   0   \n4                   0                   0                   0   \n\n   Age_Range_(70, 80]  Emb_Q  Emb_S  Fare_Mid  Fare_High_Mid  Fare_High  \\\n0                   0      0      1         0              0          0   \n1                   0      0      0         0              0          1   \n2                   0      0      1         1              0          0   \n3                   0      0      1         0              0          1   \n4                   0      0      1         1              0          0   \n\n   Class_2  Class_3  \n0        0        1  \n1        0        0  \n2        0        1  \n3        0        0  \n4        0        1  \n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Embarked\", \"Fare\"]\n\n#parameter drop_first=True = one-hot encoding, converting string to number value, RandomForestClassifier can only process int\n#X = pd.get_dummies(train_data[features], drop_first=True, dtype = int)\n#X_test = pd.get_dummies(test_data[features], drop_first=True, dtype = int)\n\n#X_test = X_test.reindex(columns=X.columns, fill_value=0)\n\nX_test = td[td.Survived.isnull()]\nX_test = X_test.drop(['Survived'], axis = 1)\n\nX = td[td.Survived.notnull()]\ny = X[\"Survived\"]\n\nprint(X.head())\nX = X.drop(['Survived'], axis = 1)\n\n\nprint(y.head())\n\nmodel = RandomForestClassifier(criterion='entropy',\nn_estimators=10000,\nmin_samples_split=100,\nmin_samples_leaf=10,\nmax_features='auto',\noob_score=True,\nrandom_state=1,\nn_jobs=-1)\n\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\nrf_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\nprint(rf_scores)","metadata":{"_kg_hide-output":false,"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:01:14.561575Z","iopub.execute_input":"2024-12-23T05:01:14.562088Z","iopub.status.idle":"2024-12-23T05:01:18.731817Z","shell.execute_reply.started":"2024-12-23T05:01:14.561994Z","shell.execute_reply":"2024-12-23T05:01:18.730728Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Sex  Family  Is_Alone  Age_Range_(0, 10]  \\\n0            1       0.0    1       1         0                  0   \n1            2       1.0    0       1         0                  0   \n2            3       1.0    0       0         1                  0   \n3            4       1.0    0       1         0                  0   \n4            5       0.0    1       0         1                  0   \n\n   Age_Range_(10, 20]  Age_Range_(20, 30]  Age_Range_(30, 40]  \\\n0                   0                   1                   0   \n1                   0                   0                   1   \n2                   0                   1                   0   \n3                   0                   0                   1   \n4                   0                   0                   1   \n\n   Age_Range_(40, 50]  Age_Range_(50, 60]  Age_Range_(60, 70]  \\\n0                   0                   0                   0   \n1                   0                   0                   0   \n2                   0                   0                   0   \n3                   0                   0                   0   \n4                   0                   0                   0   \n\n   Age_Range_(70, 80]  Emb_Q  Emb_S  Fare_Mid  Fare_High_Mid  Fare_High  \\\n0                   0      0      1         0              0          0   \n1                   0      0      0         0              0          1   \n2                   0      0      1         1              0          0   \n3                   0      0      1         0              0          1   \n4                   0      0      1         1              0          0   \n\n   Class_2  Class_3  \n0        0        1  \n1        0        0  \n2        0        1  \n3        0        0  \n4        0        1  \n0    0.0\n1    1.0\n2    1.0\n3    1.0\n4    0.0\nName: Survived, dtype: float64\n[0.72067039 0.82681564 0.84269663 0.81460674 0.80225989]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"**use XGBClassifier model which is better**# \n\nWe can loop the estimators to get the best one","metadata":{}},{"cell_type":"code","source":"\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X.columns if\n                    X[cname].nunique() < 10 and \n                    X[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the range of n_estimators to try\nn_estimators_range = [ 150, 200, 250, 400, 500, 600, 700]\n\n# Initialize variables to store best score and corresponding n_estimators\nbest_score = -np.inf\nbest_n_estimators = None\n\n#for n_estimators in n_estimators_range:\n    # Initialize the XGBoost model with the current n_estimators\n#    model = xgb.XGBClassifier(n_estimators=n_estimators)\n    \n    # Perform cross-validation and compute the mean accuracy\n#    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n#    mean_score = cv_scores.mean()\n    \n#    print(f\"n_estimators: {n_estimators}, Mean Accuracy: {mean_score}\")\n    \n    # Update the best score and n_estimators if current score is better\n#    if mean_score > best_score:\n#        best_score = mean_score\n#        best_n_estimators = n_estimators\n\n# Output the best n_estimators and its corresponding score\n#print(f\"\\nBest n_estimators: {best_n_estimators}, Best Mean Accuracy: {best_score}\")\n\nmodel = xgb.XGBClassifier(n_estimators=10000, early_stopping_rounds=50)\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X, y)\n\n# Preprocessing of validation data, get predictions\npredictions_xgb = my_pipeline.predict(X_test)\n\n#score = mean_absolute_error(y, predictions_xgb)\n#print('MAE:', score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:01:18.733869Z","iopub.execute_input":"2024-12-23T05:01:18.734258Z","iopub.status.idle":"2024-12-23T05:01:18.984837Z","shell.execute_reply.started":"2024-12-23T05:01:18.734186Z","shell.execute_reply":"2024-12-23T05:01:18.983447Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_xgb})\noutput.Survived = output.Survived.astype(int)\nprint(output.shape)\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nprint(predictions_xgb)","metadata":{"_kg_hide-output":false,"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T05:03:36.035164Z","iopub.execute_input":"2024-12-23T05:03:36.035581Z","iopub.status.idle":"2024-12-23T05:03:36.056466Z","shell.execute_reply.started":"2024-12-23T05:03:36.035523Z","shell.execute_reply":"2024-12-23T05:03:36.054719Z"}},"outputs":[{"name":"stdout","text":"(418, 2)\nYour submission was successfully saved!\n[0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n 1. 0. 1. 1. 1. 0. 1. 0. 0. 0.]\n","output_type":"stream"}],"execution_count":41}]}